{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Scott Benninger\n",
    "- Ruben Melikyan\n",
    "- Ethan Fastovsky\n",
    "- Noah Cramer\n",
    "- Shion Okino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following macroeconomic factors—aggregate consumption, unemployment, or CPI—has the strongest correlation with stock market volatility, as measured by percent change in aggregate stock market returns, in the US from 2015 Jan 1 to 2024 Jan 1?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since a couple of us are economics majors with aspirations in finance, we are particularly interested in understanding how macroeconomic indicators influence stock market dynamics and decided to take our project in such a direction. Through this project, we aim to deepen our knowledge of the economic forces that drive stock market volatility. This project not only aligns with our academic background but also prepares us for future roles in finance, where understanding these relationships is essential for informed decision-making.\n",
    "Stock market volatility is influenced by a complex interplay of economic forces, and understanding these relationships has been a longstanding focus in economic and financial research. Macroeconomic indicators such as unemployment, inflation, and interest rates serve as signals of economic health, impacting market stability and investor sentiment. Recent work recognized by the Nobel Prize in Economic Sciences highlights the role these indicators play in national economic cycles, exploring how fluctuations in key factors can signal periods of growth or downturn. One notable exploration of these dynamics is found in Why Nations Rise and Fall, which underscores how these economic indicators not only track but often predict shifts in stability and growth.\n",
    "Beyond this, in an economics course, a couple of us had to previously read part of Fama’s 1981 work, Stock Returns, Real Activity, Inflation, and Money, emphasizing the importance of understanding how key economic indicators impact stock market performance. Fama’s research found that inflation, in particular, has a significant inverse relationship with stock returns, where higher inflation diminishes purchasing power and investor confidence, often leading to market volatility and downturns. This finding is highly relevant to our project, as it illustrates the role of macroeconomic indicators—like inflation and unemployment—in shaping financial markets. By examining unemployment as a potential primary predictor of stock market volatility, we aim to build on Fama’s insights, analyzing whether this variable still holds unique predictive power over other indicators, such as the Consumer Price Index (CPI), during different economic cycles. \n",
    "\n",
    "Probably most directly useful is a research paper Chen, Roll, and Ross (1986) in Economic Forces and the Stock Market which examined how macroeconomic factors, including unemployment, influence stock market returns. They found that rising unemployment often signals reduced consumer spending and lower corporate earnings, which can drive stock prices down due to weakened investor confidence. Drawing from these findings among analysis of other variables, our project will investigate whether unemployment alone is a leading predictor of stock market volatility, or if other indicators, such as the CPI, play a more significant role.\n",
    "\n",
    "The most valuable insight from this paper is their use of an aggregated time series of stock returns as the explanatory variable. Initially, we considered using the VIX index, but after reviewing this study, we realized that an index based on market sentiment and perception might not be as suitable. The S&P 500, as a broad measure of stock market performance, offers a more direct assessment of market movements. The authors emphasize that while macroeconomic data is often smoothed and averaged, making it challenging to capture immediate market impacts, stock prices respond rapidly to new information. This difference means that stock market returns may show only a weak and noisy relationship with innovations in macroeconomic factors. Thus, using the S&P 500 allows for a timely response to economic changes, making it an effective choice for our analysis.\n",
    "\n",
    "Methodologically, the paper used a combination of time-series and cross-sectional regression techniques to analyze the relationship between stock returns and macroeconomic variables. They employ time-series analysis to identify unanticipated changes (or \"innovations\") in economic factors like industrial production, inflation, and risk premiums. They then estimate stock return sensitivities to these innovations using historical data, applying cross-sectional regressions to test the relationship between these sensitivities and subsequent asset returns. Additionally, they use something called the Fama-MacBeth procedure, where they calculate average risk premiums across multiple periods and test their significance with t-tests, allowing them to assess if systematic economic factors significantly impact expected stock returns. We can apply a similar approach by using time-series analysis to capture unexpected changes in macroeconomic factors and then  regressions to examine how these innovations relate to stock market volatility, helping us identify which factors are most predictive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that a regression analysis will reveal that among aggregate consumption, unemployment, and CPI, the unemployment rate will have the strongest correlation with stock market volatility, measured by percent change in aggregate stock market returns, in the United States from 2014 to 2024. Historically, high unemployment rates are associated with economic downturns, which tend to increase stock market volatility as investor uncertainty rises. Unemployment data is also a closely monitored indicator for forecasting potential recessions and expansions, guiding investor decisions on buying and selling. Therefore, we expect that fluctuations in the unemployment rate will be a significant predictor of stock market volatility, signaling broader economic shifts and investor sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "Dataset #1\n",
    "\n",
    "Percent Change, Daily, Seasonally Adjusted, Vintage: Current 2014-11-13 to 2024-11-12 (2024-11-12)\n",
    "\n",
    "Dataset Name: FRED Economic Data St Louis Fed S&P 500\n",
    "\n",
    "Link to the dataset: https://fred.stlouisfed.org/graph/?g=lln \n",
    "\n",
    "https://fred.stlouisfed.org/seriesBeta/SP500 \n",
    "\n",
    "Number of observations: 2610\n",
    "\n",
    "Number of variables: 2\n",
    "\n",
    "\n",
    "Dataset #2 \n",
    "\n",
    "Dataset Name:FRED Economic Data St Louis Fed Unemployment Rate\n",
    "\n",
    "Link to the dataset:https://fred.stlouisfed.org/seriesBeta/UNRATE \n",
    "\n",
    "Number of observations: 109\n",
    "\n",
    "Number of variables:2\n",
    "\n",
    "\n",
    "Dataset #3\n",
    "\n",
    "Dataset Name: FRED Economic Data St Louis Fed Aggregate Consumption Rate\n",
    "\n",
    "Link to the dataset: https://fred.stlouisfed.org/series/PCECA  \n",
    "\n",
    "Number of observations: 42\n",
    "\n",
    "Number of variables: 4\n",
    "\n",
    "\n",
    "Dataset #4\n",
    "\n",
    "Dataset Name: Core CPI seasonally adjusted 1995 - 2024\n",
    "\n",
    "Link to dataset: https://datacatalog.worldbank.org/search/dataset/0037798/Global-Economic-Monitor\n",
    "\n",
    "Number of observations: 29\n",
    "\n",
    "Number of variables: 57\n",
    "\n",
    "\n",
    "\n",
    "Dataset #1: \n",
    "FRED Economic Data - S&P 500 Percent Change\n",
    "This dataset contains daily percentage changes in the S&P 500 index over a ten-year period, from November 13, 2014, to November 12, 2024, with 2,610 observations. The primary variable, \"Percent Change,\" reflects the daily price movement of the S&P 500 and has a float data type, measured as a percentage and not seasonally adjusted, representing fluctuations in the stock market. This variable is crucial for assessing short-term market volatility and understanding trends in investor sentiment and economic conditions. Data wrangling steps will include aggregating the percent change figures so that it matches our annual analysis, handle and check for any missing data and converting the time column to a date time object. Also our data includes dates beyond necessary for our analysis so we will filter for the necessary years.\n",
    "\n",
    "\n",
    "Dataset #2: \n",
    "FRED Economic Data - Unemployment Rate\n",
    "This dataset includes 109 monthly observations of the U.S. unemployment rate, provided by the St. Louis Fed’s FRED database. The dataset consists of two variables: \"Date\" and \"Unemployment Rate,\" where the latter represents the percentage of the labor force (float data type) that is unemployed and actively seeking work. This rate is a vital economic indicator, serving as a proxy for labor market conditions and broader economic health. Data wrangling steps would be doing a linear transformation to the data such that it is percent change quarterly for time series analysis also converting the time column to a date time object through pandas for analysis.\n",
    "\n",
    "Dataset #3: FRED Economic Data - Aggregate Consumption Rate\n",
    "This dataset from the St. Louis Fed’s FRED database tracks aggregate consumption in the U.S., with 42 quarterly observations and four variables. Key variables likely include \"Date\" (indicating the quarter), \"Aggregate Consumption Rate\" (float) (representing total personal consumption expenditures as a percentage of GDP), and potentially other related metrics to contextualize consumer spending. This rate is a key economic indicator, reflecting consumer behavior trends and its contribution to overall economic growth. Preprocessing steps may involve converting time variable into date time object, converting values to consistent units or types, and handling any missing or outlier data points for reliable trend analysis.\n",
    "\n",
    "Dataset #4: Core CPI Seasonally Adjusted (1995-2024)\n",
    "This dataset provides seasonally adjusted Core Consumer Price Index (CPI) data from 1995 to 2024, sourced from the World Bank's Global Economic Monitor, with 29 annual observations and 57 variables (float). Core CPI measures inflation by tracking the price changes of goods and services, excluding volatile categories like food and energy, making it a critical indicator for understanding underlying inflation trends. Variables likely include \"Year,\" \"Core CPI\" for specific regions or countries, and potentially additional economic indicators for comparative analysis. Data wrangling may involve reshaping the dataset for time series analysis, handling any missing converting time to a date time object, removing columns for other countries as our analysis is limited to the US.\n",
    "\n",
    "\n",
    "Plan for Combining Datasets:\n",
    "The datasets we downloaded from FRED gave us the flexibility of choosing exact date ranges and units for measurement. Therefore we will be merging the datasets quarterly for a more smooth time series analysis. This matches with the data downloaded from the world bank and very convenient to merge using the time column, which is more convenient by convertin the time column to date time objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed packages\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Daily_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>-3.007878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>5.384284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>-1.668783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>0.877221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>1.087943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>-1.720630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>-4.943132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>-2.138358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>8.608871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>4.367699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  Daily_Return\n",
       "0   2015-01-31     -3.007878\n",
       "1   2015-02-28      5.384284\n",
       "2   2015-03-31     -1.668783\n",
       "3   2015-04-30      0.877221\n",
       "4   2015-05-31      1.087943\n",
       "..         ...           ...\n",
       "103 2023-08-31     -1.720630\n",
       "104 2023-09-30     -4.943132\n",
       "105 2023-10-31     -2.138358\n",
       "106 2023-11-30      8.608871\n",
       "107 2023-12-31      4.367699\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION \n",
    "\n",
    "# read in data\n",
    "fp = Path('data') / 'SP500.csv'\n",
    "sp500 = pd.read_csv(fp)\n",
    "\n",
    "# Ensure the DATE column is in datetime format\n",
    "sp500['DATE'] = pd.to_datetime(sp500['DATE'])\n",
    "\n",
    "# Filter the data for dates between 2015-01-01 and 2024-01-01\n",
    "sp500 = sp500[(sp500['DATE'] >= '2015-01-01') & (sp500['DATE'] <= '2024-01-01')]\n",
    "\n",
    "#Dropping non numeric data points from SP500 column\n",
    "sp500 = sp500.reset_index(drop=True)\n",
    "sp500['SP500'] = pd.to_numeric(sp500['SP500'], errors='coerce')\n",
    "\n",
    "# Drop rows where 'SP500' is NaN (i.e., non-numeric rows)\n",
    "sp500 = sp500.dropna(subset=['SP500'])\n",
    "\n",
    "# Convert remaining values to float\n",
    "sp500['SP500'] = sp500['SP500'].astype(float)\n",
    "\n",
    "# Calculate daily returns (percent change)\n",
    "sp500['Daily_Return'] = sp500['SP500'].pct_change() * 100  # daily returns in percentage\n",
    "\n",
    "# Drop the first row, as it will contain NaN due to the percent change calculation\n",
    "sp500 = sp500.dropna(subset=['Daily_Return'])\n",
    "\n",
    "# Aggregate daily returns to get monthly returns by summing them\n",
    "monthly_sp500 = sp500.resample('ME', on='DATE')['Daily_Return'].sum().reset_index()\n",
    "\n",
    "# Display the monthly data\n",
    "monthly_sp500\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  UNRATE\n",
       "0   2015-01-01     5.7\n",
       "1   2015-02-01     5.5\n",
       "2   2015-03-01     5.4\n",
       "3   2015-04-01     5.4\n",
       "4   2015-05-01     5.6\n",
       "..         ...     ...\n",
       "104 2023-09-01     3.8\n",
       "105 2023-10-01     3.8\n",
       "106 2023-11-01     3.7\n",
       "107 2023-12-01     3.7\n",
       "108 2024-01-01     3.7\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the unemployment rate data\n",
    "fp = Path('data') / 'UNRATE.csv'\n",
    "unem = pd.read_csv(fp)\n",
    "\n",
    "# Ensure the DATE column is in datetime format\n",
    "unem['DATE'] = pd.to_datetime(unem['DATE'])\n",
    "\n",
    "# Filter the data for dates between 2015-01-01 and 2024-01-01\n",
    "unem = unem[(unem['DATE'] >= '2015-01-01') & (unem['DATE'] <= '2024-01-01')]\n",
    "unem.reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Consumption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12066.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>12116.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>12176.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>12209.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>12275.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>19024.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>19069.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>19151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>19289.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>19308.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE      PCE\n",
       "0   2015-01-01  12066.7\n",
       "1   2015-02-01  12116.6\n",
       "2   2015-03-01  12176.1\n",
       "3   2015-04-01  12209.1\n",
       "4   2015-05-01  12275.4\n",
       "..         ...      ...\n",
       "104 2023-09-01  19024.9\n",
       "105 2023-10-01  19069.5\n",
       "106 2023-11-01  19151.0\n",
       "107 2023-12-01  19289.9\n",
       "108 2024-01-01  19308.5\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the aggregate consumption data\n",
    "fp = Path('data') / 'PCE.csv'\n",
    "agg = pd.read_csv(fp)\n",
    "\n",
    "# Ensure the DATE column is in datetime format\n",
    "agg['DATE'] = pd.to_datetime(agg['DATE'])\n",
    "\n",
    "# Filter the data for dates between 2015-01-01 and 2024-01-01\n",
    "agg = agg[(agg['DATE'] >= '2015-01-01') & (agg['DATE'] <= '2024-01-01')]\n",
    "agg.reset_index().drop(columns = 'index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core CPI Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>United States</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>108.6923</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>108.8559</td>\n",
       "      <td>2015-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>109.1201</td>\n",
       "      <td>2015-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>109.3880</td>\n",
       "      <td>2015-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>109.5430</td>\n",
       "      <td>2015-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>140.7967</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>141.1348</td>\n",
       "      <td>2023-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>141.5695</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>141.9593</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>142.5163</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     United States       DATE\n",
       "242       108.6923 2015-01-01\n",
       "243       108.8559 2015-02-01\n",
       "244       109.1201 2015-03-01\n",
       "245       109.3880 2015-04-01\n",
       "246       109.5430 2015-05-01\n",
       "..             ...        ...\n",
       "346       140.7967 2023-09-01\n",
       "347       141.1348 2023-10-01\n",
       "348       141.5695 2023-11-01\n",
       "349       141.9593 2023-12-01\n",
       "350       142.5163 2024-01-01\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the core CPI data\n",
    "fp = Path('data') / 'CORECPI.xlsx'\n",
    "CPI_data = pd.read_excel(fp)\n",
    "\n",
    "# grab only the United States data and the dates\n",
    "CPI_data = CPI_data[['United States', 'Unnamed: 0']]\n",
    "\n",
    "# rename the Date column appropriately\n",
    "CPI_data.rename(columns={'Unnamed: 0': 'DATE'}, inplace=True)\n",
    "\n",
    "# Convert the Date column from 'YYYYMM' format to datetime format\n",
    "CPI_data['DATE'] = pd.to_datetime(CPI_data['DATE'], format='%YM%m', errors='coerce')\n",
    "\n",
    "# Filter the data for dates between 2015-01-01 and 2024-01-01\n",
    "CPI_data = CPI_data[(CPI_data['DATE'] >= '2015-01-01') & (CPI_data['DATE'] <= '2024-01-01')]\n",
    "\n",
    "CPI_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Daily_Return</th>\n",
       "      <th>United States</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>PCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>-3.007878</td>\n",
       "      <td>108.6923</td>\n",
       "      <td>5.7</td>\n",
       "      <td>12066.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>5.384284</td>\n",
       "      <td>108.8559</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12116.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>-1.668783</td>\n",
       "      <td>109.1201</td>\n",
       "      <td>5.4</td>\n",
       "      <td>12176.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0.877221</td>\n",
       "      <td>109.3880</td>\n",
       "      <td>5.4</td>\n",
       "      <td>12209.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>1.087943</td>\n",
       "      <td>109.5430</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12275.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  Daily_Return  United States  UNRATE      PCE\n",
       "0 2015-01-01     -3.007878       108.6923     5.7  12066.7\n",
       "1 2015-02-01      5.384284       108.8559     5.5  12116.6\n",
       "2 2015-03-01     -1.668783       109.1201     5.4  12176.1\n",
       "3 2015-04-01      0.877221       109.3880     5.4  12209.1\n",
       "4 2015-05-01      1.087943       109.5430     5.6  12275.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'DATE' to year and month only, to ensure monthly consistency\n",
    "for df, name in zip([monthly_sp500, CPI_data, unem, agg], [\"monthly_sp500\", \"CPI_data\", \"unem\", \"agg\"]):\n",
    "    # Convert to datetime if needed\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    # Keep only the year and month part\n",
    "    df['DATE'] = df['DATE'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Perform the outer merge on 'DATE' after adjusting all to monthly\n",
    "merged_data = (\n",
    "    monthly_sp500\n",
    "    .merge(CPI_data, on='DATE', how='outer')\n",
    "    .merge(unem, on='DATE', how='outer')\n",
    "    .merge(agg, on='DATE', how='outer')\n",
    ")\n",
    "\n",
    "# Filter to ensure the date range is from January 2015 to December 2023\n",
    "merged_data = merged_data[(merged_data['DATE'] >= '2015-01-01') & (merged_data['DATE'] <= '2023-12-31')]\n",
    "\n",
    "# Check for null values in merged data\n",
    "assert merged_data.isnull().sum(axis = 0).sum() == 0\n",
    "\n",
    "#display the data\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be ethical concerns regarding \n",
    "\n",
    "Biases/Privacy/Terms of Use: World Bank U.S. data is generally public and follows strict data privacy and usage standards. However, potential biases can arise due to the structure of reported metrics and reliance on government and institutional sources, which might reflect particular economic priorities or omit certain demographic nuances.\n",
    "Potential Biases in Composition: U.S. World Bank data might underrepresent specific subpopulations or regional economic conditions, especially if it aggregates across states or overlooks informal economies. Additionally, while U.S. data is generally comprehensive, it might still exclude or simplify information from marginalized communities or rural areas, which could skew results.  When analyzing the stock market, it is possible that it will not adequately represent activity by lower income populations as this market tends to be influenced primarily by wealthy investors.\n",
    "Detecting Biases: To detect these biases, we’ll review data for representativeness across different demographics and states, looking for gaps in coverage or skewed trends. Cross-checking with other sources, like the Bureau of Labor Statistics, will also help validate findings and identify potential issues during analysis.\n",
    "Other Issues (Privacy & Equitable Impact): While anonymized, the data could still emphasize economic conditions linked to sensitive attributes, such as income disparities. To avoid unintended biases, we’ll contextualize findings carefully to avoid reinforcing stereotypes or inequities.\n",
    "Handling Issues Identified: We’ll adjust models to account for possible underreporting in certain states or demographics and provide transparency about these limitations in our communication. Sensitivity analyses and clear statements about data limitations will also help ensure fair, unbiased interpretations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our discord regularly for any updates\n",
    "Respond promptly to texts in our group chat. \n",
    "Let everyone know if you are unable to attend our meeting times\n",
    "Be communicative and transparent if you can’t get your share of the work done\n",
    "Be understanding \n",
    "\n",
    "\n",
    "Scott - Clean Data, Create initial visualizations \n",
    "\n",
    "Ruben  -  Clean Data, Create initial visualizations \n",
    "\n",
    "Ethan -  Double Check Visualizations and Data - Analysis, Discussion \n",
    "\n",
    "Noah - Analysis, Conclusion, Discussion\n",
    "\n",
    "Shion - Analysis, Conclusion, Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All meetings are tentatively set to 11:30 a.m., however further communication prior to our meetings will ensue**\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 10/28  |  11:30 AM | Read Ruben's proposed ideas; brainstorm topics/questions  | Finalize our question and understand our roles within the project going forward| \n",
    "| 11/11  |  11:30 AM |  Checkpoint #1: Data due on Wednesday. Ruben and Scott should have our datasets cleaned and ready to have analysis performed on it| Ruben and Scott will present the cleaned data and we will discuss how to continue on with our project. Discuss possible analytical approaches\n",
    "| 11/25  | 11:30 AM  | Checkpoint #2: EDA* is due on Wednesday. Scott and Ruben should finalize wrangling; Ethan and Noah should continue to perform EDA, | Address any concerns with the EDA process, and discuss further advanced analysis and new directions to take the project  |\n",
    "| 12/02| 11:30 AM  | wrap up any data analysis and go through any completed work | Figure out the best time to film our final video, and discuss anything that should be changed.|\n",
    "| 12/09  | 11:30 AM  | Shion should conclude our paper and go through intently and fix anything that needs fixing | Wrap up our project. Ensure we are happy with our results and have the project turned in 2 days early to avoid any last minute issues. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
